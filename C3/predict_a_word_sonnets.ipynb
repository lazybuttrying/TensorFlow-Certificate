{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "predict a word - sonnets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOCamE/lAFoc0yvuogJziGe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lazybuttrying/TensorFlow-Certificate/blob/main/C3/predict_a_word_sonnets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4by_pF15kYbu"
      },
      "source": [
        "# üê±‚Äçüèç Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muXx_D9MkYyD"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.keras.utils as ku \n",
        "import tensorflow as tf\n",
        "import numpy as np "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9Y56FROkb59"
      },
      "source": [
        "# üìÑ Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5mH8hTEkZy4",
        "outputId": "b7674443-4cb9-4049-cfab-fb2d4e5beac8"
      },
      "source": [
        "# sonnets.txt\n",
        "!gdown --id 108jAePKK4R3BVYBbYJZ32JWUwxeMg20K\n",
        "\n",
        "data = open('./sonnets.txt').read()\n",
        "\n",
        "corpus = data.lower().split(\"\\n\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=108jAePKK4R3BVYBbYJZ32JWUwxeMg20K\n",
            "To: /content/sonnets.txt\n",
            "\r  0% 0.00/93.6k [00:00<?, ?B/s]\r100% 93.6k/93.6k [00:00<00:00, 20.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NodhJETFkmaJ"
      },
      "source": [
        "# ‚úÇÔ∏è Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kdr-uAWPkegf"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYH9NhrVlA2-"
      },
      "source": [
        "# üêç Change to Sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD5HB91wlB2-"
      },
      "source": [
        "# create input sequences using list of tokens\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4G2nEF7lMA1"
      },
      "source": [
        "# üå´Ô∏è Padding: Match the lenght of all setence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnDxYoHDlMUi"
      },
      "source": [
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXyigD8UlOOv"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woV1Fu5dlTAT"
      },
      "source": [
        "# create predictors and label\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "label = ku.to_categorical(label, num_classes=total_words)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dHhxd6Zl60F"
      },
      "source": [
        "# üïã Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2_rwOu8lTWg",
        "outputId": "47ad9261-4273-4eaa-8488-23610ac9ceac"
      },
      "source": [
        "### START CODE HERE\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))# Your Embedding Layer)\n",
        "model.add(Bidirectional(LSTM(150, return_sequences = True)))# An LSTM Layer)\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words/2, \n",
        "                activation='relu', \n",
        "                kernel_regularizer=regularizers.l2(0.01)))# A Dense Layer including regularizers)\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 10, 100)           321100    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 10, 300)          301200    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 10, 300)           0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100)               160400    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1605)              162105    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3211)              5156866   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,101,671\n",
            "Trainable params: 6,101,671\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD-2hYlQmwyi"
      },
      "source": [
        "# Pick an optimizer\n",
        "model.compile(loss='categorical_crossentropy', # predict a wordÎäî categorical_crossentropy!!\n",
        "              optimizer='adam',  #tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "              metrics=['accuracy'])\n",
        "### END CODE HERE\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyYIXHv3nF4r"
      },
      "source": [
        "# üèÉ‚Äç‚ôÇÔ∏è fit: training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tegnc2uNnNfI"
      },
      "source": [
        "model_save_path = \"./\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(model_save_path, \n",
        "                                                save_weights_only=True, \n",
        "                                                save_best_only=True, \n",
        "                                                monitor='val_loss', #val_sparse_categorical_accuracy \n",
        "                                                verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7dRZykgl_KT",
        "outputId": "1015dee4-c207-412d-8e34-fbe137fa5964"
      },
      "source": [
        " history = model.fit(predictors, \n",
        "                     label, \n",
        "                     epochs=100, #150\n",
        "                     callbacks = [checkpoint],\n",
        "                     verbose=1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 6.9111 - accuracy: 0.0210WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 56s 103ms/step - loss: 6.9111 - accuracy: 0.0210\n",
            "Epoch 2/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 6.5034 - accuracy: 0.0243WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 6.5034 - accuracy: 0.0243\n",
            "Epoch 3/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 6.4119 - accuracy: 0.0219WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 6.4119 - accuracy: 0.0219\n",
            "Epoch 4/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 6.3030 - accuracy: 0.0275WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 6.3030 - accuracy: 0.0275\n",
            "Epoch 5/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 6.2088 - accuracy: 0.0345WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 6.2088 - accuracy: 0.0345\n",
            "Epoch 6/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 6.1437 - accuracy: 0.0372WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 6.1437 - accuracy: 0.0372\n",
            "Epoch 7/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 6.0778 - accuracy: 0.0400WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 105ms/step - loss: 6.0778 - accuracy: 0.0400\n",
            "Epoch 8/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 6.0048 - accuracy: 0.0438WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 105ms/step - loss: 6.0048 - accuracy: 0.0438\n",
            "Epoch 9/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 5.9197 - accuracy: 0.0500WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 105ms/step - loss: 5.9197 - accuracy: 0.0500\n",
            "Epoch 10/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 5.8183 - accuracy: 0.0556WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 52s 108ms/step - loss: 5.8183 - accuracy: 0.0556\n",
            "Epoch 11/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 5.7208 - accuracy: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 5.7208 - accuracy: 0.0602\n",
            "Epoch 12/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 5.6334 - accuracy: 0.0655WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 104ms/step - loss: 5.6334 - accuracy: 0.0655\n",
            "Epoch 13/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 5.5415 - accuracy: 0.0698WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 5.5415 - accuracy: 0.0698\n",
            "Epoch 14/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 5.4607 - accuracy: 0.0739WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 5.4607 - accuracy: 0.0739\n",
            "Epoch 15/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 5.3674 - accuracy: 0.0806WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 5.3674 - accuracy: 0.0806\n",
            "Epoch 16/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 5.2798 - accuracy: 0.0865WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 104ms/step - loss: 5.2798 - accuracy: 0.0865\n",
            "Epoch 17/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 5.1881 - accuracy: 0.0901WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 105ms/step - loss: 5.1881 - accuracy: 0.0901\n",
            "Epoch 18/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 5.0917 - accuracy: 0.0964WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 104ms/step - loss: 5.0917 - accuracy: 0.0964\n",
            "Epoch 19/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 5.0005 - accuracy: 0.1033WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 105ms/step - loss: 5.0005 - accuracy: 0.1033\n",
            "Epoch 20/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.9105 - accuracy: 0.1090WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 105ms/step - loss: 4.9105 - accuracy: 0.1090\n",
            "Epoch 21/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.8153 - accuracy: 0.1145WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 104ms/step - loss: 4.8153 - accuracy: 0.1145\n",
            "Epoch 22/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.7206 - accuracy: 0.1217WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 105ms/step - loss: 4.7206 - accuracy: 0.1217\n",
            "Epoch 23/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.6317 - accuracy: 0.1311WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 4.6317 - accuracy: 0.1311\n",
            "Epoch 24/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.5377 - accuracy: 0.1385WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 104ms/step - loss: 4.5377 - accuracy: 0.1385\n",
            "Epoch 25/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.4506 - accuracy: 0.1471WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 104ms/step - loss: 4.4506 - accuracy: 0.1471\n",
            "Epoch 26/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.3551 - accuracy: 0.1575WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 105ms/step - loss: 4.3551 - accuracy: 0.1575\n",
            "Epoch 27/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.2624 - accuracy: 0.1667WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 4.2624 - accuracy: 0.1667\n",
            "Epoch 28/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.1749 - accuracy: 0.1793WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 4.1749 - accuracy: 0.1793\n",
            "Epoch 29/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.0879 - accuracy: 0.1885WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 4.0879 - accuracy: 0.1885\n",
            "Epoch 30/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.0020 - accuracy: 0.1995WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 4.0020 - accuracy: 0.1995\n",
            "Epoch 31/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 3.9153 - accuracy: 0.2136WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 105ms/step - loss: 3.9153 - accuracy: 0.2136\n",
            "Epoch 32/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 3.8305 - accuracy: 0.2311WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 3.8305 - accuracy: 0.2311\n",
            "Epoch 33/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 3.7505 - accuracy: 0.2406WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 3.7505 - accuracy: 0.2406\n",
            "Epoch 34/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 3.6744 - accuracy: 0.2612WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 3.6744 - accuracy: 0.2612\n",
            "Epoch 35/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 3.5959 - accuracy: 0.2782WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 3.5959 - accuracy: 0.2782\n",
            "Epoch 36/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 3.5256 - accuracy: 0.2868WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 3.5256 - accuracy: 0.2868\n",
            "Epoch 37/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 3.4476 - accuracy: 0.3080WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 3.4476 - accuracy: 0.3080\n",
            "Epoch 38/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 3.3724 - accuracy: 0.3192WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 3.3724 - accuracy: 0.3192\n",
            "Epoch 39/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 3.3099 - accuracy: 0.3360WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 105ms/step - loss: 3.3099 - accuracy: 0.3360\n",
            "Epoch 40/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 3.2471 - accuracy: 0.3542WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 3.2471 - accuracy: 0.3542\n",
            "Epoch 41/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 3.1733 - accuracy: 0.3675WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 3.1733 - accuracy: 0.3675\n",
            "Epoch 42/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 3.1016 - accuracy: 0.3803WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 3.1016 - accuracy: 0.3803\n",
            "Epoch 43/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 3.0497 - accuracy: 0.3961WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 3.0497 - accuracy: 0.3961\n",
            "Epoch 44/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 2.9898 - accuracy: 0.4073WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 2.9898 - accuracy: 0.4073\n",
            "Epoch 45/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 2.9228 - accuracy: 0.4245WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 2.9228 - accuracy: 0.4245\n",
            "Epoch 46/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 2.8700 - accuracy: 0.4344WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 2.8700 - accuracy: 0.4344\n",
            "Epoch 47/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 2.8145 - accuracy: 0.4475WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 2.8145 - accuracy: 0.4475\n",
            "Epoch 48/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 2.7537 - accuracy: 0.4582WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 2.7537 - accuracy: 0.4582\n",
            "Epoch 49/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 2.7089 - accuracy: 0.4734WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 2.7089 - accuracy: 0.4734\n",
            "Epoch 50/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 2.6572 - accuracy: 0.4825WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 2.6572 - accuracy: 0.4825\n",
            "Epoch 51/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 2.5975 - accuracy: 0.4968WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 2.5975 - accuracy: 0.4968\n",
            "Epoch 52/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 2.5623 - accuracy: 0.5058WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 2.5623 - accuracy: 0.5058\n",
            "Epoch 53/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 2.5138 - accuracy: 0.5127WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 2.5138 - accuracy: 0.5127\n",
            "Epoch 54/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 2.4615 - accuracy: 0.5290WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 2.4615 - accuracy: 0.5290\n",
            "Epoch 55/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 2.4103 - accuracy: 0.5423WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 2.4103 - accuracy: 0.5423\n",
            "Epoch 56/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 2.3607 - accuracy: 0.5554WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 2.3607 - accuracy: 0.5554\n",
            "Epoch 57/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 2.3300 - accuracy: 0.5600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 2.3300 - accuracy: 0.5600\n",
            "Epoch 58/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 2.2950 - accuracy: 0.5644WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 2.2950 - accuracy: 0.5644\n",
            "Epoch 59/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 2.2475 - accuracy: 0.5782WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 2.2475 - accuracy: 0.5782\n",
            "Epoch 60/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 2.2088 - accuracy: 0.5867WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 2.2088 - accuracy: 0.5867\n",
            "Epoch 61/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 2.1718 - accuracy: 0.5948WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 2.1718 - accuracy: 0.5948\n",
            "Epoch 62/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 2.1349 - accuracy: 0.6018WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 2.1349 - accuracy: 0.6018\n",
            "Epoch 63/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 2.0887 - accuracy: 0.6165WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 2.0887 - accuracy: 0.6165\n",
            "Epoch 64/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 2.0702 - accuracy: 0.6153WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 2.0702 - accuracy: 0.6153\n",
            "Epoch 65/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 2.0188 - accuracy: 0.6305WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 2.0188 - accuracy: 0.6305\n",
            "Epoch 66/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.9889 - accuracy: 0.6358WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 1.9889 - accuracy: 0.6358\n",
            "Epoch 67/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.9728 - accuracy: 0.6354WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 104ms/step - loss: 1.9728 - accuracy: 0.6354\n",
            "Epoch 68/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.9444 - accuracy: 0.6412WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 1.9444 - accuracy: 0.6412\n",
            "Epoch 69/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.9118 - accuracy: 0.6543WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 1.9118 - accuracy: 0.6543\n",
            "Epoch 70/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.8642 - accuracy: 0.6596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 105ms/step - loss: 1.8642 - accuracy: 0.6596\n",
            "Epoch 71/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.8527 - accuracy: 0.6663WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 1.8527 - accuracy: 0.6663\n",
            "Epoch 72/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.8200 - accuracy: 0.6682WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 1.8200 - accuracy: 0.6682\n",
            "Epoch 73/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.7908 - accuracy: 0.6769WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 1.7908 - accuracy: 0.6769\n",
            "Epoch 74/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.7832 - accuracy: 0.6795WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 1.7832 - accuracy: 0.6795\n",
            "Epoch 75/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.7433 - accuracy: 0.6865WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 1.7433 - accuracy: 0.6865\n",
            "Epoch 76/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.7100 - accuracy: 0.6969WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 1.7100 - accuracy: 0.6969\n",
            "Epoch 77/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.6875 - accuracy: 0.7007WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 105ms/step - loss: 1.6875 - accuracy: 0.7007\n",
            "Epoch 78/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.6791 - accuracy: 0.7010WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 105ms/step - loss: 1.6791 - accuracy: 0.7010\n",
            "Epoch 79/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.6475 - accuracy: 0.7093WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 1.6475 - accuracy: 0.7093\n",
            "Epoch 80/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.6291 - accuracy: 0.7121WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 1.6291 - accuracy: 0.7121\n",
            "Epoch 81/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.6057 - accuracy: 0.7192WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 1.6057 - accuracy: 0.7192\n",
            "Epoch 82/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.5828 - accuracy: 0.7224WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 1.5828 - accuracy: 0.7224\n",
            "Epoch 83/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.5503 - accuracy: 0.7289WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 1.5503 - accuracy: 0.7289\n",
            "Epoch 84/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.5395 - accuracy: 0.7311WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 1.5395 - accuracy: 0.7311\n",
            "Epoch 85/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.5133 - accuracy: 0.7370WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 104ms/step - loss: 1.5133 - accuracy: 0.7370\n",
            "Epoch 86/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.5031 - accuracy: 0.7368WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 105ms/step - loss: 1.5031 - accuracy: 0.7368\n",
            "Epoch 87/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.4848 - accuracy: 0.7419WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 1.4848 - accuracy: 0.7419\n",
            "Epoch 88/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.4762 - accuracy: 0.7413WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 104ms/step - loss: 1.4762 - accuracy: 0.7413\n",
            "Epoch 89/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.4468 - accuracy: 0.7489WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 106ms/step - loss: 1.4468 - accuracy: 0.7489\n",
            "Epoch 90/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.4439 - accuracy: 0.7472WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 105ms/step - loss: 1.4439 - accuracy: 0.7472\n",
            "Epoch 91/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.4328 - accuracy: 0.7513WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 52s 108ms/step - loss: 1.4328 - accuracy: 0.7513\n",
            "Epoch 92/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.4134 - accuracy: 0.7550WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 106ms/step - loss: 1.4134 - accuracy: 0.7550\n",
            "Epoch 93/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.3933 - accuracy: 0.7596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 106ms/step - loss: 1.3933 - accuracy: 0.7596\n",
            "Epoch 94/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.3823 - accuracy: 0.7613WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 105ms/step - loss: 1.3823 - accuracy: 0.7613\n",
            "Epoch 95/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.3650 - accuracy: 0.7623WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 1.3650 - accuracy: 0.7623\n",
            "Epoch 96/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.3427 - accuracy: 0.7670WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 1.3427 - accuracy: 0.7670\n",
            "Epoch 97/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.3284 - accuracy: 0.7707WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 105ms/step - loss: 1.3284 - accuracy: 0.7707\n",
            "Epoch 98/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.3414 - accuracy: 0.7653WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 104ms/step - loss: 1.3414 - accuracy: 0.7653\n",
            "Epoch 99/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.3161 - accuracy: 0.7722WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 105ms/step - loss: 1.3161 - accuracy: 0.7722\n",
            "Epoch 100/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 1.2982 - accuracy: 0.7745WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "484/484 [==============================] - 51s 105ms/step - loss: 1.2982 - accuracy: 0.7745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILUdMkFcnSxw"
      },
      "source": [
        "# üíø Get a best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQfmJe-OnTLd"
      },
      "source": [
        "#model.load_weights(model_save_path)\n",
        "model.save(\"predict a word - sonnets.h5\")\n",
        "\n",
        "# https://teddylee777.github.io/tensorflow/news-sarcasm\n",
        "# Dense LayerÎ•º ÍπäÍ≤å ÏåìÏïÑ Î≥¥Í±∞ÎÇò,\n",
        "# Conv1D ÌòπÏùÄ LSTMÏùÑ Îëê Í≤πÏúºÎ°ú ÏåìÍ±∞ÎÇò\n",
        "# optimizer(adam)Ïùò learning_rateÎ•º ÎÜíÏù¥Í±∞ÎÇò ÎÇÆÏ∂îÎäî Î∞©ÏãùÏúºÎ°ú\n",
        "# Î™®Îç∏ÏùÑ Í∞úÏÑ†Ìï¥Î≥¥Ïûê"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRG8DLLbnYs-"
      },
      "source": [
        "#üìà Plot accuracy & loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "Af7qBNBQnZCX",
        "outputId": "5ab4864d-f79d-4b16-bab3-ce5eb7a37102"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.title('Training accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQIQL94jnihs"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPBJtuUonjJo",
        "outputId": "e9f86ae4-340b-42cb-f1d7-42bb7afa8f75"
      },
      "source": [
        "seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list, verbose=0), axis=1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help me Obi Wan Kenobi, you're my only hope but i have hell away dead writ must thee be hence thine words know thine eyes all thine eyes alone to me be less respect find dead gone on all thy dead days more cross ' best of cheeks love that love to thee tend tend tend needing exceed tend twain hate other strong friend cold strong friend strong friend best best in thee doth me be shown ever much dead kind on dear friend lie with thy friend to such ill say i all thee show his heart ' not so mine eye untrue despair so dear alone eye\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrGROOQ_toQ1"
      },
      "source": [
        "# +) With Higher Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF3_mCdHuw3h"
      },
      "source": [
        "model_save_path = \"./\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(model_save_path, \n",
        "                                                save_weights_only=True, \n",
        "                                                save_best_only=True, \n",
        "                                                monitor='loss', #val_sparse_categorical_accuracy \n",
        "                                                verbose=1)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBUxbbccpJws"
      },
      "source": [
        "# Pick an optimizer\n",
        "model.compile(loss='categorical_crossentropy', # predict a wordÎäî categorical_crossentropy!!\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),\n",
        "              metrics=['accuracy'])\n",
        "### END CODE HERE\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S8HzdjuMtxCO",
        "outputId": "4e6073f3-f7d8-4f11-8c95-d6eb23e0f506"
      },
      "source": [
        " history = model.fit(predictors, \n",
        "                     label, \n",
        "                     epochs=100, \n",
        "                     callbacks = [checkpoint],\n",
        "                     verbose=1)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 5.4777 - accuracy: 0.0813\n",
            "Epoch 00001: loss improved from inf to 5.47768, saving model to ./\n",
            "484/484 [==============================] - 55s 103ms/step - loss: 5.4777 - accuracy: 0.0813\n",
            "Epoch 2/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 5.1840 - accuracy: 0.0911\n",
            "Epoch 00002: loss improved from 5.47768 to 5.18399, saving model to ./\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 5.1840 - accuracy: 0.0911\n",
            "Epoch 3/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 5.0735 - accuracy: 0.0943\n",
            "Epoch 00003: loss improved from 5.18399 to 5.07347, saving model to ./\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 5.0735 - accuracy: 0.0943\n",
            "Epoch 4/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.9571 - accuracy: 0.1007\n",
            "Epoch 00004: loss improved from 5.07347 to 4.95708, saving model to ./\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 4.9571 - accuracy: 0.1007\n",
            "Epoch 5/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.9280 - accuracy: 0.1011\n",
            "Epoch 00005: loss improved from 4.95708 to 4.92799, saving model to ./\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 4.9280 - accuracy: 0.1011\n",
            "Epoch 6/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.8527 - accuracy: 0.1044\n",
            "Epoch 00006: loss improved from 4.92799 to 4.85269, saving model to ./\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 4.8527 - accuracy: 0.1044\n",
            "Epoch 7/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.7744 - accuracy: 0.1038\n",
            "Epoch 00007: loss improved from 4.85269 to 4.77443, saving model to ./\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 4.7744 - accuracy: 0.1038\n",
            "Epoch 8/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.7136 - accuracy: 0.1079\n",
            "Epoch 00008: loss improved from 4.77443 to 4.71356, saving model to ./\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 4.7136 - accuracy: 0.1079\n",
            "Epoch 9/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.7021 - accuracy: 0.1108\n",
            "Epoch 00009: loss improved from 4.71356 to 4.70212, saving model to ./\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 4.7021 - accuracy: 0.1108\n",
            "Epoch 10/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.6633 - accuracy: 0.1138\n",
            "Epoch 00010: loss improved from 4.70212 to 4.66328, saving model to ./\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 4.6633 - accuracy: 0.1138\n",
            "Epoch 11/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.6335 - accuracy: 0.1153\n",
            "Epoch 00011: loss improved from 4.66328 to 4.63350, saving model to ./\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 4.6335 - accuracy: 0.1153\n",
            "Epoch 12/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.5934 - accuracy: 0.1153\n",
            "Epoch 00012: loss improved from 4.63350 to 4.59338, saving model to ./\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 4.5934 - accuracy: 0.1153\n",
            "Epoch 13/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.5537 - accuracy: 0.1221\n",
            "Epoch 00013: loss improved from 4.59338 to 4.55372, saving model to ./\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 4.5537 - accuracy: 0.1221\n",
            "Epoch 14/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.5285 - accuracy: 0.1235\n",
            "Epoch 00014: loss improved from 4.55372 to 4.52854, saving model to ./\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 4.5285 - accuracy: 0.1235\n",
            "Epoch 15/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.5050 - accuracy: 0.1250\n",
            "Epoch 00015: loss improved from 4.52854 to 4.50504, saving model to ./\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 4.5050 - accuracy: 0.1250\n",
            "Epoch 16/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.4707 - accuracy: 0.1255\n",
            "Epoch 00016: loss improved from 4.50504 to 4.47068, saving model to ./\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 4.4707 - accuracy: 0.1255\n",
            "Epoch 17/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.4403 - accuracy: 0.1336\n",
            "Epoch 00017: loss improved from 4.47068 to 4.44029, saving model to ./\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 4.4403 - accuracy: 0.1336\n",
            "Epoch 18/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.4444 - accuracy: 0.1323\n",
            "Epoch 00018: loss did not improve from 4.44029\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 4.4444 - accuracy: 0.1323\n",
            "Epoch 19/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.4178 - accuracy: 0.1322\n",
            "Epoch 00019: loss improved from 4.44029 to 4.41781, saving model to ./\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 4.4178 - accuracy: 0.1322\n",
            "Epoch 20/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.3864 - accuracy: 0.1391\n",
            "Epoch 00020: loss improved from 4.41781 to 4.38641, saving model to ./\n",
            "484/484 [==============================] - 50s 103ms/step - loss: 4.3864 - accuracy: 0.1391\n",
            "Epoch 21/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.3685 - accuracy: 0.1347\n",
            "Epoch 00021: loss improved from 4.38641 to 4.36847, saving model to ./\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 4.3685 - accuracy: 0.1347\n",
            "Epoch 22/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.3465 - accuracy: 0.1383\n",
            "Epoch 00022: loss improved from 4.36847 to 4.34652, saving model to ./\n",
            "484/484 [==============================] - 51s 105ms/step - loss: 4.3465 - accuracy: 0.1383\n",
            "Epoch 23/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.3458 - accuracy: 0.1367\n",
            "Epoch 00023: loss improved from 4.34652 to 4.34578, saving model to ./\n",
            "484/484 [==============================] - 51s 106ms/step - loss: 4.3458 - accuracy: 0.1367\n",
            "Epoch 24/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.3413 - accuracy: 0.1370\n",
            "Epoch 00024: loss improved from 4.34578 to 4.34134, saving model to ./\n",
            "484/484 [==============================] - 51s 105ms/step - loss: 4.3413 - accuracy: 0.1370\n",
            "Epoch 25/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.3380 - accuracy: 0.1363\n",
            "Epoch 00025: loss improved from 4.34134 to 4.33804, saving model to ./\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 4.3380 - accuracy: 0.1363\n",
            "Epoch 26/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.2995 - accuracy: 0.1420\n",
            "Epoch 00026: loss improved from 4.33804 to 4.29952, saving model to ./\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 4.2995 - accuracy: 0.1420\n",
            "Epoch 27/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.3129 - accuracy: 0.1407\n",
            "Epoch 00027: loss did not improve from 4.29952\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 4.3129 - accuracy: 0.1407\n",
            "Epoch 28/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.2960 - accuracy: 0.1423\n",
            "Epoch 00028: loss improved from 4.29952 to 4.29602, saving model to ./\n",
            "484/484 [==============================] - 50s 104ms/step - loss: 4.2960 - accuracy: 0.1423\n",
            "Epoch 29/100\n",
            "484/484 [==============================] - ETA: 0s - loss: 4.3036 - accuracy: 0.1403\n",
            "Epoch 00029: loss did not improve from 4.29602\n",
            "484/484 [==============================] - 51s 105ms/step - loss: 4.3036 - accuracy: 0.1403\n",
            "Epoch 30/100\n",
            "128/484 [======>.......................] - ETA: 36s - loss: 4.2038 - accuracy: 0.1509"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-1fe39dce5bcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     verbose=1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io9JTBJVtzsH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}